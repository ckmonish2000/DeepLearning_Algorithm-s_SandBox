{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":1,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader\nimport torch.nn.functional as F\nimport torchvision\nfrom torchvision.utils import make_grid\nfrom torchvision.datasets import CIFAR10\nimport torchvision.transforms as transforms\n","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ds=CIFAR10(root=\"data\",download=True,transform=transforms.ToTensor())","execution_count":6,"outputs":[{"output_type":"stream","text":"Files already downloaded and verified\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"mean=[]\nstd=[]\nfor x in range(3):\n    mean.append(i[x].mean())\n    std.append(i[x].std())\nprint(mean)\nprint(std)","execution_count":15,"outputs":[{"output_type":"stream","text":"[tensor(0.5537), tensor(0.4122), tensor(0.2511)]\n[tensor(0.1595), tensor(0.1665), tensor(0.1603)]\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"trans={\n    \"train\":transforms.Compose([\n        transforms.Resize(32),\n        transforms.RandomCrop(30,padding=True,padding_mode=\"reflect\"),\n        transforms.RandomHorizontalFlip(),\n        transforms.RandomRotation(180),\n        transforms.ToTensor(),\n        transforms.Normalize(mean,std)\n    ]),\n    \"val\":transforms.Compose([\n        transforms.Resize(32),\n        transforms.ToTensor(),\n        transforms.Normalize(mean,std)\n    ])\n}","execution_count":17,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\nbatch_size=128","execution_count":22,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ds=CIFAR10(root=\"data\",transform=trans[\"train\"],train=True)\nts=ds=CIFAR10(root=\"data\",transform=trans[\"val\"],train=False)\ndl=DataLoader(ds,batch_size=batch_size,shuffle=True,pin_memory=True,num_workers=3)\ntl=DataLoader(ts,batch_size=batch_size,shuffle=True,pin_memory=True,num_workers=3)","execution_count":21,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def convBlock(in_channel,out_channel,pool):\n    layers=[nn.Conv2d(in_channel,out_channel,kernel_size=3,padding=1),\n            nn.BatchNorm2d(out_channel),\n            nn.ReLU()\n            ]\n    if pool:layers.append(nn.MaxPool2d(2,2))\n    return nn.Sequential(*layers)","execution_count":52,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Resnet(nn.Module):\n    def __init__(self,in_channel,num_classes):\n        super().__init__()\n        self.conv1=convBlock(in_channel,12,pool=True)\n        self.conv2=convBlock(12,24,pool=True)\n        self.res1=nn.Sequential(convBlock(24,24,pool=False),convBlock(24,24,pool=False))\n        self.conv3=convBlock(24,48,pool=True)\n        self.conv4=convBlock(48,124,pool=True)\n        self.res2=nn.Sequential(convBlock(124,124,pool=False),convBlock(124,124,pool=False))\n        self.classify=nn.Sequential(nn.Flatten(),nn.Linear(124*2*2,num_classes))\n    \n    def forward(self,x):\n        out=self.conv1(x)\n        out=self.conv2(out)\n        out=self.res1(out)+out\n        out=self.conv3(out)\n        out=self.conv4(out)\n        out=self.res2(out)+out\n        out=self.classify(out)\n        return out","execution_count":116,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in dl:\n    dta=i\n    break","execution_count":58,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dta[0].shape","execution_count":59,"outputs":[{"output_type":"execute_result","execution_count":59,"data":{"text/plain":"torch.Size([128, 3, 32, 32])"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"model=Resnet(in_channel=3,num_classes=10)","execution_count":117,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dt=torch.unsqueeze(dta[0][0],dim=0)\nmodel(dt)","execution_count":119,"outputs":[{"output_type":"execute_result","execution_count":119,"data":{"text/plain":"tensor([[ 0.4061,  0.0772, -0.0696,  2.1243, -0.5149, -0.1483, -0.0998,  2.6446,\n         -0.2732, -0.3534]], grad_fn=<AddmmBackward>)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def accuracy(outputs, labels):\n    _, preds = torch.max(outputs, dim=1)\n    return torch.tensor(torch.sum(preds == labels).item() / len(preds))","execution_count":125,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def fit(epochs,max_lr,model,loss,wd,grad_clip,tl):\n    model.to(device)\n    optim=torch.optim.Adam(model.parameters(),weight_decay=wd,lr=max_lr)\n    sch=torch.optim.lr_scheduler.OneCycleLR(optim,max_lr=max_lr,epochs=epochs,steps_per_epoch=len(tl))\n    for epoch in range(epochs):\n        model.train()\n        for i,j in tl:\n            i=i.to(device)\n            j=j.to(device)\n            pred=model(i)\n            ls=loss(pred,j)\n            ls.backward()\n            if grad_clip:\n                nn.utils.clip_grad_value_(model.parameters(),grad_clip)\n            optim.step()\n            optim.zero_grad()\n            sch.step()\n            acc=accuracy(pred,j)\n        print(f\"loss={ls} acc={acc}\")\n        ","execution_count":129,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model=Resnet(in_channel=3,num_classes=10)\nloss=nn.CrossEntropyLoss()\nwDecay=0.01\ngradclip=1\nmaxlr=0.0001\nepochs=20\n\n","execution_count":130,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fit(epochs,maxlr,model,loss,wDecay,gradclip,dl)","execution_count":131,"outputs":[{"output_type":"stream","text":"loss=2.293839693069458 acc=0.1875\nloss=1.902808666229248 acc=0.4375\nloss=2.0383846759796143 acc=0.3125\nloss=1.9003742933273315 acc=0.25\nloss=1.8170111179351807 acc=0.375\nloss=1.5147364139556885 acc=0.4375\nloss=0.8258908987045288 acc=0.8125\nloss=0.8549389839172363 acc=0.6875\nloss=1.1511389017105103 acc=0.4375\nloss=1.019219160079956 acc=0.6875\nloss=1.0341283082962036 acc=0.625\nloss=0.589480459690094 acc=0.9375\nloss=0.8795186281204224 acc=0.6875\nloss=0.9090612530708313 acc=0.5625\nloss=0.9567352533340454 acc=0.8125\nloss=0.8263826370239258 acc=0.75\nloss=0.6835426688194275 acc=0.8125\nloss=1.1141713857650757 acc=0.5\nloss=0.7557905912399292 acc=0.75\nloss=0.4566907584667206 acc=0.875\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def evaluate(epochs,model,loss,tl):\n    for epoch in range(epochs):\n        model.eval()\n        for i,j in tl:\n            i=i.to(device)\n            j=j.to(device)\n            pred=model(i)\n            ls=loss(pred,j)\n            acc=accuracy(pred,j)\n        print(f\"loss={ls} acc={acc}\")\n        ","execution_count":133,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"evaluate(epochs,model,loss,tl)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}