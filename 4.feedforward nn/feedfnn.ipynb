{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\n\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":26,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import torch \nimport torch.nn as nn\nfrom torch.utils.data import DataLoader\nimport torchvision as vision\nfrom torchvision.datasets import MNIST\nfrom torchvision.utils import make_grid","execution_count":27,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data=MNIST(root=\"data\",download=True,transform=vision.transforms.ToTensor())\ndata","execution_count":28,"outputs":[{"output_type":"execute_result","execution_count":28,"data":{"text/plain":"Dataset MNIST\n    Number of datapoints: 60000\n    Root location: data\n    Split: Train\n    StandardTransform\nTransform: ToTensor()"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"# Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"def accuracy(outputs, labels):\n    _, preds = torch.max(outputs, dim=1)\n    return torch.tensor(torch.sum(preds == labels).item() / len(preds))","execution_count":29,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class feedf(nn.Module):\n    def __init__(self,ip_size,h_size,op_size):\n        super().__init__()\n        self.linear1=nn.Linear(ip_size,h_size)\n        self.linear2=nn.Linear(h_size,op_size)\n    \n    def forward(self,xb):\n        xb=xb.view(xb.size(0),-1)\n        out=self.linear1(xb)\n        out=nn.functional.relu(out)\n        out=self.linear2(out)\n        return out\n    \n    def training_step(self,batch):\n        img,l=batch\n        pred=self(img)\n        loss=nn.functional.cross_entropy(pred,l)\n        return loss\n    \n    def validation_step(self,batch):\n        img,l=batch\n        pred=self(img)\n        loss=nn.functional.cross_entropy(pred,l)\n        acc=accuracy(pred,l)\n        return {\"val_loss\":loss,\"val_acc\":acc}\n    \n    def validation_epoch_end(self,output):\n        loss=[x[\"val_loss\"] for x in output]      \n        acc=[x[\"val_acc\"] for x in output]      \n        loss=torch.stack(loss).mean()\n        acc=torch.stack(acc).mean()\n        return {\"loss\":loss.item(),\"acc\":acc.item()}\n    \n    def epoch_end(self, epoch, result):\n        print(\"Epoch [{}], val_loss: {:.4f}, val_acc: {:.4f}\".format(epoch, result['val_loss'], result['val_acc']))\n    \n            \n            \n        ","execution_count":30,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ts,vs=torch.utils.data.random_split(data,[50000,10000])\ntl=DataLoader(ts,batch_size=128,pin_memory=True,num_workers=2)\nvl=DataLoader(vs,batch_size=128,pin_memory=True,num_workers=2)","execution_count":31,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model=feedf(784,32,10)","execution_count":32,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i,j in tl:\n    pred=model(i)\n    loss=nn.functional.cross_entropy(pred,j)\n    print(loss)\n    break\n    ","execution_count":33,"outputs":[{"output_type":"stream","text":"tensor(2.3089, grad_fn=<NllLossBackward>)\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# GPU"},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_device():\n    if torch.cuda.is_available():\n        return torch.device(\"cuda\")\n    return torch.device(\"cpu\")","execution_count":34,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def to_device(data,device):\n    if isinstance(data,(list,tuple)):\n        return [to_device(x,device) for x in data]\n    return data.to(device)","execution_count":35,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class DeviceDL():\n    def __init__(self,dl,device):\n        self.dl=dl\n        self.device=device\n    def __iter__(self):\n        for i in self.dl:\n            yield to_device(i,self.device)\n    def __len__(self):\n        return len(self.dl)","execution_count":36,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dev=get_device()\ntl=DeviceDL(tl,dev)\nvl=DeviceDL(vl,dev)","execution_count":37,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i,j in tl:\n    print(i)\n    print(j)\n    break","execution_count":38,"outputs":[{"output_type":"stream","text":"tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n          [0., 0., 0.,  ..., 0., 0., 0.],\n          [0., 0., 0.,  ..., 0., 0., 0.],\n          ...,\n          [0., 0., 0.,  ..., 0., 0., 0.],\n          [0., 0., 0.,  ..., 0., 0., 0.],\n          [0., 0., 0.,  ..., 0., 0., 0.]]],\n\n\n        [[[0., 0., 0.,  ..., 0., 0., 0.],\n          [0., 0., 0.,  ..., 0., 0., 0.],\n          [0., 0., 0.,  ..., 0., 0., 0.],\n          ...,\n          [0., 0., 0.,  ..., 0., 0., 0.],\n          [0., 0., 0.,  ..., 0., 0., 0.],\n          [0., 0., 0.,  ..., 0., 0., 0.]]],\n\n\n        [[[0., 0., 0.,  ..., 0., 0., 0.],\n          [0., 0., 0.,  ..., 0., 0., 0.],\n          [0., 0., 0.,  ..., 0., 0., 0.],\n          ...,\n          [0., 0., 0.,  ..., 0., 0., 0.],\n          [0., 0., 0.,  ..., 0., 0., 0.],\n          [0., 0., 0.,  ..., 0., 0., 0.]]],\n\n\n        ...,\n\n\n        [[[0., 0., 0.,  ..., 0., 0., 0.],\n          [0., 0., 0.,  ..., 0., 0., 0.],\n          [0., 0., 0.,  ..., 0., 0., 0.],\n          ...,\n          [0., 0., 0.,  ..., 0., 0., 0.],\n          [0., 0., 0.,  ..., 0., 0., 0.],\n          [0., 0., 0.,  ..., 0., 0., 0.]]],\n\n\n        [[[0., 0., 0.,  ..., 0., 0., 0.],\n          [0., 0., 0.,  ..., 0., 0., 0.],\n          [0., 0., 0.,  ..., 0., 0., 0.],\n          ...,\n          [0., 0., 0.,  ..., 0., 0., 0.],\n          [0., 0., 0.,  ..., 0., 0., 0.],\n          [0., 0., 0.,  ..., 0., 0., 0.]]],\n\n\n        [[[0., 0., 0.,  ..., 0., 0., 0.],\n          [0., 0., 0.,  ..., 0., 0., 0.],\n          [0., 0., 0.,  ..., 0., 0., 0.],\n          ...,\n          [0., 0., 0.,  ..., 0., 0., 0.],\n          [0., 0., 0.,  ..., 0., 0., 0.],\n          [0., 0., 0.,  ..., 0., 0., 0.]]]], device='cuda:0')\ntensor([2, 7, 2, 8, 4, 9, 9, 1, 9, 6, 0, 6, 3, 8, 9, 9, 6, 2, 1, 1, 8, 5, 7, 9,\n        9, 0, 6, 8, 1, 1, 5, 1, 3, 4, 3, 7, 3, 6, 3, 3, 1, 0, 6, 2, 0, 7, 4, 3,\n        7, 1, 0, 4, 4, 7, 6, 8, 0, 3, 6, 3, 3, 8, 5, 3, 6, 6, 4, 9, 7, 5, 6, 2,\n        6, 2, 1, 0, 6, 2, 5, 7, 4, 0, 7, 5, 8, 1, 2, 5, 0, 4, 4, 9, 2, 6, 0, 2,\n        7, 9, 9, 8, 5, 4, 0, 8, 5, 8, 7, 5, 5, 0, 8, 5, 6, 9, 3, 4, 2, 6, 5, 6,\n        8, 8, 1, 6, 3, 1, 6, 4], device='cuda:0')\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def evaluate(model, val_loader):\n    outputs = [model.validation_step(batch) for batch in val_loader]\n    return model.validation_epoch_end(outputs)\n\ndef fit(epoch,lr,model,train_loader,valid_loader):\n    history=[]\n    optim=torch.optim.SGD(model.parameters(),lr=lr)\n    for i in range(epoch):\n        for i in train_loader:\n            loss=model.training_step(i)\n            loss.backward()\n            optim.step()\n            optim.zero_grad()\n        result=evaluate(model,valid_loader)\n#         model.epoch_end(epoch,result)\n        history.append(result)\n    return history\n            \n        ","execution_count":39,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dev=get_device()\nmodel=feedf(784,32,10)\nto_device(model,dev)","execution_count":40,"outputs":[{"output_type":"execute_result","execution_count":40,"data":{"text/plain":"feedf(\n  (linear1): Linear(in_features=784, out_features=32, bias=True)\n  (linear2): Linear(in_features=32, out_features=10, bias=True)\n)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"fit(10,0.05,model,tl,vl)","execution_count":42,"outputs":[{"output_type":"execute_result","execution_count":42,"data":{"text/plain":"[{'loss': 0.2699311673641205, 'acc': 0.9234572649002075},\n {'loss': 0.25744953751564026, 'acc': 0.9270173907279968},\n {'loss': 0.2470676153898239, 'acc': 0.9309731125831604},\n {'loss': 0.23835764825344086, 'acc': 0.9324564933776855},\n {'loss': 0.23059599101543427, 'acc': 0.9347310066223145},\n {'loss': 0.22361010313034058, 'acc': 0.9359177350997925},\n {'loss': 0.2173796147108078, 'acc': 0.9371044039726257},\n {'loss': 0.2115447223186493, 'acc': 0.9378955960273743},\n {'loss': 0.20620688796043396, 'acc': 0.9393789768218994},\n {'loss': 0.2012401521205902, 'acc': 0.9408623576164246}]"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in model.parameters():\n    print(i.device)","execution_count":43,"outputs":[{"output_type":"execute_result","execution_count":43,"data":{"text/plain":"<generator object Module.parameters at 0x7f337412eb50>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}